services:
  postgres:
    image: postgres:15
    restart: always
    environment:
      POSTGRES_USER: n8n
      POSTGRES_PASSWORD: n8n_password
      POSTGRES_DB: n8n
    volumes:
      - n8n-postgres-data:/var/lib/postgresql/data

  github-models-proxy:
    build: .
    restart: always
    ports:
      - "11434:11434"
    environment:
      - GITHUB_TOKEN=${GITHUB_TOKEN}  # Your GitHub PAT with 'models:read'
      - N8N_API_KEY=${N8N_API_KEY}  # If your proxy uses this for auth
      - N8N_BASE_URL=${N8N_BASE_URL:-http://n8n:5678}
    volumes:
      - .:/app
    # Add health check if tools cause long hangs
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:11434/v1/models"]
      interval: 30s
      timeout: 10s
      retries: 3

  # Chat UI - Web interface for the GitHub Models API
  chat-ui:
    image: nginx:alpine
    restart: always
    ports:
      - "8080:80"  # Chat UI accessible at http://localhost:8080
    volumes:
      - ./web:/usr/share/nginx/html:ro
      # Mount the entire nginx.conf directory so default.conf is correctly treated as a file within it
      - ./web/nginx.conf:/etc/nginx/conf.d:ro
    depends_on:
      - github-models-proxy

  n8n:
    image: n8nio/n8n
    restart: always
    ports:
      - "5678:5678"
    environment:
      - DB_TYPE=postgresdb
      - DB_POSTGRESDB_HOST=postgres
      - DB_POSTGRESDB_PORT=5432
      - DB_POSTGRESDB_DATABASE=n8n
      - DB_POSTGRESDB_USER=n8n
      - DB_POSTGRESDB_PASSWORD=n8n_password
      - GENERIC_TIMEZONE=Europe/Amsterdam
      - N8N_BASIC_AUTH_ACTIVE=true
      - N8N_BASIC_AUTH_USER=admin@example.com       # pas aan naar eigen gebruiker
      - N8N_BASIC_AUTH_PASSWORD=secret  # pas aan naar eigen wachtwoord
      # Point directly to GitHub Models
      # - OPENAI_API_BASE=https://models.github.ai/v1
      # - OPENAI_API_KEY=${GITHUB_TOKEN}       # Use GitHub PAT with 'models:read' scope
      # - OPENAI_MODEL=openai/gpt-4o           # Explicit model for tools support
      # OpenAI Configuration for GitHub Models Proxy
      - OPENAI_API_BASE=http://github-models-proxy:11434/v1
      - OPENAI_API_KEY=dummy-key-for-github-proxy
      - OPENAI_MODEL=gpt-4o  # Explicitly set a tool-supporting model in n8n env if needed
      # Give node more heap memory to avoid OOM during heavy workflows
      - N8N_MEMORY_LIMIT=2048
      - NODE_OPTIONS=--max-old-space-size=2048
    # Attempt to set a container memory limit for Compose environments that honor it
    mem_limit: 2g
    depends_on:
      - postgres
    # - github-models-proxy
    volumes:
      - n8n-data:/home/node/.n8n

volumes:
  n8n-data:
  n8n-postgres-data:
